{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSDS 7331 - Lab One: Visualization and Data Processing\n",
    "\n",
    "### Investigators\n",
    "- [Matt Baldree](mailto:mbaldree@smu.edu?subject=lab1)\n",
    "- [Tom Elkins](telkins@smu.edu?subject=lab1)\n",
    "- [Autin Kelly](ajkelly@smu.edu?subject=lab1)\n",
    "- [Murali Parthasarathy](mparthasarathy@smu.edu?subject=lab1)\n",
    "\n",
    "\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:5px;'>\n",
    "    <h3>Lab Instructions</h3>\n",
    "    <p>You are to perform analysis of a data set: exploring the statistical summaries of the features,\n",
    "visualizing the attributes, and making conclusions from the visualizations and analysis. Follow the\n",
    "CRISP-DM framework in your analysis (you are not performing all of the CRISP-DM outline, only\n",
    "the portions relevant to understanding and visualization). This report is worth 20% of the final\n",
    "grade. Please upload a report (one per team) with all code used, visualizations, and text in a single\n",
    "document. The format of the document can be PDF, *.ipynb, or HTML. You can write the report in\n",
    "whatever format you like, but it is easiest to turn in the rendered iPython notebook.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='business_understanding'></a>\n",
    "## Business Understanding\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:10px;'>\n",
    "<h3>Business Understanding (<b>10 points total</b>)</h3>\n",
    "    <ol><li>Describe the purpose of the data set you selected (i.e., why was this data collected in\n",
    "the first place?).</li>\n",
    "    <li>Describe how you would define and measure the outcomes from the\n",
    "dataset. That is, why is this data important and how do you know if you have mined\n",
    "useful knowledge from the dataset?</li>\n",
    "    <li>How would you measure the effectiveness of a\n",
    "good prediction algorithm? Be specific.</li></ol>\n",
    "</div>\n",
    "\n",
    "### 1. Purpose of Data Set\n",
    "The data set chosen for lab 1 is the 2015 Washington DC Metro Crime inspired from a Kaggle data set found at https://www.kaggle.com/vinchinzu/dc-metro-crime-data. The data set was obtained by following the steps found on the [Using the Crime Map Application](http://mpdc.dc.gov/node/200622) page. This site allowed us to download all eight wards from 01/01/2015 to 12/31/2015 as an exported CSV files. These individual ward files were then merged together into a single file for our use. This data set contains 36,493 entries and 18 attributes that are both continuous and discrete. This satisfies the data set requirement for a minimum of 30,000 entries and 10 attributes which are both continuous and discrete. Further definition of this data set will be discussed in the [Data Understanding](#data_understanding) section.\n",
    "\n",
    "![Ward Map](images/wards_small.png \"Washington DC Wards\") \n",
    "<p style='text-align: center;'>\n",
    "Washington DC Metro Ward Map\n",
    "</p>\n",
    "\n",
    "The crime data is published by the Washington DC Metro police department daily (see below image) to provide their residents a clear picture of crime trends as they actually happen. The data is shared with its residents such as Advisory Neighborhood Commissions to help the police determine how to keep neighborhoods safe. The data is also analyzed to determine the effectiveness of current investments such as putting more officers on the streets, buying police more tools, and launching community partnerships, see [Washington DC Metro Police Department report](http://mpdc.dc.gov/publication/mpd-annual-report-2015) for more details.\n",
    "\n",
    "![Ward Map](images/dc_2015_crime.tiff \"Washington DC Year End Crime Data\") \n",
    "<p style='text-align: center;'>\n",
    "Washington DC Metro 2015 Year End Crime Data\n",
    "</p>\n",
    "\n",
    "### 2. Importance of the Data Set\n",
    "This data set could be used to predict the number of violent and property crimes in police district given time of day, day of week, and other factors. This would allow the police department to appropriate adequate resources to each district to respond and possibly prevent the crimes.\n",
    "\n",
    "### 3. Measurement of Importance\n",
    "The measurement of the importance would be to perform a validation on the machine learning model that was trained on the data set to predict the number of crimes that would be committed in a police district. The prediction error would be reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_understanding\"></a>\n",
    "## Data Understanding\n",
    "\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:10px;'>\n",
    "<h3>Data Understanding (<b>80 points total</b>)</h3>\n",
    "    <ol><li>[<b>10 points</b>] Describe the meaning and type of data (scale, values, etc.) for each\n",
    "attribute in the data file.</li>\n",
    "    <li>[<b>15 points</b>] Verify data quality: Explain any missing values, duplicate data, and outliers.\n",
    "Are those mistakes? How do you deal with these problems? Be specific.</li>\n",
    "    <li>[<b>10 points</b>] Give simple, appropriate statistics (range, mode, mean, median, variance,\n",
    "counts, etc.) for the most important attributes and describe what they mean or if you\n",
    "found something interesting. Note: You can also use data from other sources for\n",
    "comparison. Explain the significance of the statistics run and why they are meaningful.</li>\n",
    "    <li>[<b>15 points</b>] Visualize the most important attributes appropriately (at least 5 attributes).\n",
    "Important: Provide an interpretation for each chart. Explain for each attribute why the\n",
    "chosen visualization is appropriate.</li>\n",
    "    <li>[<b>15 points</b>] Explore relationships between attributes: Look at the attributes via scatter\n",
    "plots, correlation, cross-tabulation, group-wise averages, etc. as appropriate. Explain\n",
    "any interesting relationships.</li>\n",
    "    <li>[<b>10 points</b>] Identify and explain interesting relationships between features and the class\n",
    "you are trying to predict (i.e., relationships with variables and the target classification).</li>\n",
    "    <li>[<b>5 points</b>] Are there other features that could be added to the data or created from\n",
    "existing features? Which ones?</li></ol>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Import the PANDAS library so we can work with dataframes\n",
    "import pandas as pd\n",
    "\n",
    "#  Read in the crime data from the combined CSV file\n",
    "dc = pd.read_csv('data/DC_Crime_2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information about Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36493 entries, 0 to 36492\n",
      "Data columns (total 18 columns):\n",
      "REPORT_DAT              36493 non-null object\n",
      "SHIFT                   36493 non-null object\n",
      "OFFENSE                 36493 non-null object\n",
      "METHOD                  36493 non-null object\n",
      "BLOCK                   36493 non-null object\n",
      "DISTRICT                36446 non-null float64\n",
      "PSA                     36445 non-null float64\n",
      "WARD                    36493 non-null int64\n",
      "ANC                     36493 non-null object\n",
      "NEIGHBORHOOD_CLUSTER    36076 non-null object\n",
      "BLOCK_GROUP             36379 non-null object\n",
      "CENSUS_TRACT            36379 non-null float64\n",
      "VOTING_PRECINCT         36480 non-null object\n",
      "CCN                     36493 non-null int64\n",
      "XBLOCK                  36493 non-null float64\n",
      "YBLOCK                  36493 non-null float64\n",
      "START_DATE              36493 non-null object\n",
      "END_DATE                36241 non-null object\n",
      "dtypes: float64(5), int64(2), object(11)\n",
      "memory usage: 5.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# dataframe info\n",
    "print dc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           DISTRICT           PSA          WARD  CENSUS_TRACT           CCN  \\\n",
      "count  36446.000000  36445.000000  36493.000000  36379.000000  3.649300e+04   \n",
      "mean       3.697196    374.298395      4.421259   6211.275791  1.511937e+07   \n",
      "std        1.947438    194.524001      2.339270   3146.217537  1.087825e+05   \n",
      "min        1.000000    101.000000      1.000000    100.000000  6.155556e+06   \n",
      "25%        2.000000    206.000000      2.000000   3400.000000  1.505885e+07   \n",
      "50%        4.000000    401.000000      5.000000   7000.000000  1.511063e+07   \n",
      "75%        5.000000    506.000000      6.000000   8904.000000  1.516497e+07   \n",
      "max        7.000000    708.000000      8.000000  11100.000000  1.619697e+07   \n",
      "\n",
      "              XBLOCK         YBLOCK  \n",
      "count   36493.000000   36493.000000  \n",
      "mean   399301.346694  137698.576414  \n",
      "std      3113.115343    3424.503748  \n",
      "min    390147.000000  127300.000000  \n",
      "25%    397228.000000  136027.000000  \n",
      "50%    398878.000000  137622.530000  \n",
      "75%    401257.000000  139839.000000  \n",
      "max    407806.000000  147292.000000  \n"
     ]
    }
   ],
   "source": [
    "# summary statistics\n",
    "print dc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Record from Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT_DAT                                 06/24/2015 23:10\n",
      "SHIFT                                              MIDNIGHT\n",
      "OFFENSE                                         THEFT/OTHER\n",
      "METHOD                                               OTHERS\n",
      "BLOCK                   600 - 699 BLOCK OF MORTON STREET NW\n",
      "DISTRICT                                                  3\n",
      "PSA                                                     302\n",
      "WARD                                                      1\n",
      "ANC                                                      1A\n",
      "NEIGHBORHOOD_CLUSTER                              Cluster 2\n",
      "BLOCK_GROUP                                        003200 3\n",
      "CENSUS_TRACT                                           3200\n",
      "VOTING_PRECINCT                                 Precinct 38\n",
      "CCN                                                15095285\n",
      "XBLOCK                                               398044\n",
      "YBLOCK                                               140473\n",
      "START_DATE                                 06/23/2015 21:40\n",
      "END_DATE                                   06/24/2015 21:30\n",
      "Name: 1234, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print an example \n",
    "print dc.ix[1234]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Field Definitions\n",
    "The [Crime Definitions](http://crimemap.dc.gov/CrimeDefinitions.aspx) provides detail definitions of codes used in this data set.\n",
    "\n",
    "|Column|Data Type|Value Range|Description|Missing|\n",
    "|:-----|:--------|:----------|:----------|:-----:|\n",
    "|REPORT_DAT|Date/Time|01/01/2015 00:00:00 - 12/31/2015 23:59:59|The date/time the offense was *reported*|0|\n",
    "|SHIFT|Nominal|Day = 0700-1500, Evening = 1500-2300, Midnight = 2300-0700|The duty shift that responded to the call|0|\n",
    "|OFFENSE|Nominal|Various|The category of crime committed (from the Crime Definitions link above)|0|\n",
    "|METHOD|Nominal|\"OTHERS\", \"GUN\", \"KNIFE\"|A qualifier to the Offense that flags special considerations, such as the use of a gun|0|\n",
    "|BLOCK|Nominal|Varies|The street and block identifier|0|\n",
    "|DISTRICT|Integer|1-7|The police district|47 (0.13%)|\n",
    "|PSA|Integer|{1-7}(01-08}: 101-108,...,701-708|Police Service Area|48 (0.13%)|\n",
    "|WARD|Integer|1-8|The political Ward identifier|0|\n",
    "|ANC|Nominal|{1-8}{A-G}|Advisory Neighborhood Commission|0|\n",
    "|NEIGHBORHOOD_CLUSTER|Nominal|\"Cluster \"{1-39}|Neighborhood identifier|417 (1.14%)|\n",
    "|BLOCK_GROUP|Nominal|{CENSUS_TRACT}{space}{1-6}|Subdivision within a tract|114 (0.31%)\n",
    "|CENSUS_TRACT|Integer|Discontinuous values between 100 and 11100|Land management tract identifier|114 (0.31%)|\n",
    "|VOTING_PRECINCT|Nominal|\"Precinct \"{1-143}|Political subdivision|12 (0.03%)|\n",
    "|CCN|Integer|Discontinuous values between 14151815 and 15403340|Criminal Complaint Number - unique to each report|0|\n",
    "|XBLOCK|Ratio|min: 390,147; max: 407,806|Eastern coordinate of crime scene (meters)|0|\n",
    "|YBLOCK|Ratio|min: 147,292; max: 127,300|Northern coordinate of crime scene (meters)|0|\n",
    "|START_DATE|Date/Time|Varies|The earliest the crime *might* have been committed|0|\n",
    "|END_DATE|Date/Time|Varies|The latest the crime *might* have been committed|252 (0.69%)|\n",
    "\n",
    "Given that we have geo-physical coordinates, we believe we can impute some of the missing geo-political values (such as Police District)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Verify data quality: Explain any missing values, duplicate data, and outliers. Are those mistakes? How do you deal with these problems? Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Data Frame Columns to Correct Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: describe the conversions including the mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36493 entries, 0 to 36492\n",
      "Data columns (total 18 columns):\n",
      "REPORT_DAT              36493 non-null datetime64[ns]\n",
      "SHIFT                   36493 non-null int64\n",
      "OFFENSE                 33246 non-null float64\n",
      "METHOD                  35326 non-null float64\n",
      "BLOCK                   434 non-null float64\n",
      "DISTRICT                36446 non-null float64\n",
      "PSA                     36445 non-null float64\n",
      "WARD                    36493 non-null int64\n",
      "ANC                     4384 non-null float64\n",
      "NEIGHBORHOOD_CLUSTER    4537 non-null float64\n",
      "BLOCK_GROUP             1672 non-null float64\n",
      "CENSUS_TRACT            36379 non-null float64\n",
      "VOTING_PRECINCT         2829 non-null float64\n",
      "CCN                     36493 non-null int64\n",
      "XBLOCK                  36493 non-null float64\n",
      "YBLOCK                  36493 non-null float64\n",
      "START_DATE              36493 non-null datetime64[ns]\n",
      "END_DATE                36241 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](3), float64(12), int64(3)\n",
      "memory usage: 5.0 MB\n",
      "None\n",
      "               REPORT_DAT  SHIFT  OFFENSE  METHOD  BLOCK  DISTRICT    PSA  \\\n",
      "0     2015-03-04 12:05:00      0      0.0     0.0    0.0       3.0  305.0   \n",
      "1     2015-01-22 09:00:00      0      1.0     0.0    1.0       4.0  408.0   \n",
      "2     2015-01-03 21:20:00      1      0.0     0.0    2.0       3.0  302.0   \n",
      "3     2015-01-05 12:44:00      0      0.0     0.0    3.0       3.0  306.0   \n",
      "4     2015-01-20 07:01:00      0      1.0     0.0    4.0       3.0  302.0   \n",
      "5     2015-01-20 06:38:00      2      2.0     0.0    5.0       3.0  305.0   \n",
      "6     2015-01-20 11:30:00      0      3.0     0.0    6.0       3.0  304.0   \n",
      "7     2015-01-20 12:00:00      0      0.0     0.0    7.0       4.0  408.0   \n",
      "8     2015-01-01 23:48:00      2      4.0     1.0    8.0       3.0  305.0   \n",
      "9     2015-01-04 01:28:00      2      1.0     0.0    9.0       3.0  304.0   \n",
      "10    2015-01-08 17:57:00      1      NaN     0.0    NaN       3.0  302.0   \n",
      "11    2015-01-05 16:05:00      1      1.0     0.0    NaN       3.0  301.0   \n",
      "12    2015-01-05 18:45:00      1      4.0     0.0    NaN       4.0  408.0   \n",
      "13    2015-01-10 22:00:00      1      4.0     NaN    NaN       3.0  303.0   \n",
      "14    2015-01-10 00:00:00      2      NaN     1.0    NaN       4.0  409.0   \n",
      "15    2015-01-05 20:00:00      1      4.0     0.0    NaN       4.0  408.0   \n",
      "16    2015-01-05 20:40:00      1      1.0     0.0    NaN       3.0  304.0   \n",
      "17    2015-01-05 20:58:00      1      0.0     0.0    NaN       3.0  304.0   \n",
      "18    2015-01-05 23:06:00      2      4.0     0.0    NaN       3.0  302.0   \n",
      "19    2015-01-05 23:30:00      2      4.0     1.0    NaN       3.0  306.0   \n",
      "20    2015-01-02 11:19:00      0      1.0     0.0    NaN       4.0  409.0   \n",
      "21    2015-01-13 15:00:00      0      1.0     0.0    NaN       4.0  409.0   \n",
      "22    2015-01-16 15:53:00      1      4.0     NaN    NaN       3.0  302.0   \n",
      "23    2015-01-16 15:16:00      1      3.0     NaN    NaN       3.0  301.0   \n",
      "24    2015-01-16 19:00:00      1      4.0     0.0    NaN       3.0  302.0   \n",
      "25    2015-01-11 04:30:00      2      3.0     NaN    NaN       3.0  303.0   \n",
      "26    2015-01-18 04:45:00      2      0.0     0.0    NaN       3.0  303.0   \n",
      "27    2015-01-11 13:08:00      0      0.0     0.0    NaN       3.0  302.0   \n",
      "28    2015-01-11 14:57:00      0      1.0     0.0    NaN       3.0  302.0   \n",
      "29    2015-01-11 17:17:00      1      0.0     0.0    NaN       3.0  302.0   \n",
      "...                   ...    ...      ...     ...    ...       ...    ...   \n",
      "36463 2015-03-06 14:04:00      0      0.0     0.0    NaN       7.0  708.0   \n",
      "36464 2015-03-12 14:13:00      0      0.0     0.0    NaN       7.0  703.0   \n",
      "36465 2015-12-21 09:09:00      0      0.0     0.0    NaN       7.0  708.0   \n",
      "36466 2015-12-09 22:18:00      1      3.0     1.0    NaN       7.0  706.0   \n",
      "36467 2015-12-22 20:53:00      1      NaN     0.0    NaN       7.0  707.0   \n",
      "36468 2015-12-23 11:40:00      0      4.0     1.0    NaN       7.0  703.0   \n",
      "36469 2015-12-23 11:57:00      0      NaN     0.0    NaN       7.0  704.0   \n",
      "36470 2015-11-27 19:23:00      1      2.0     0.0    NaN       7.0  701.0   \n",
      "36471 2015-11-29 23:03:00      2      0.0     0.0    NaN       7.0  703.0   \n",
      "36472 2015-11-30 05:30:00      2      NaN     0.0    NaN       7.0  701.0   \n",
      "36473 2015-11-03 22:55:00      1      0.0     0.0    NaN       7.0  703.0   \n",
      "36474 2015-11-03 22:09:00      1      3.0     1.0    NaN       7.0  703.0   \n",
      "36475 2015-12-12 10:07:00      0      0.0     0.0    NaN       7.0  701.0   \n",
      "36476 2015-12-12 10:37:00      0      2.0     0.0    NaN       7.0  706.0   \n",
      "36477 2015-12-26 00:30:00      2      3.0     0.0    NaN       7.0  703.0   \n",
      "36478 2015-12-26 01:19:00      2      3.0     0.0    NaN       7.0  707.0   \n",
      "36479 2015-11-30 16:18:00      1      4.0     0.0    NaN       7.0  704.0   \n",
      "36480 2015-12-14 13:17:00      0      NaN     0.0    NaN       7.0  703.0   \n",
      "36481 2015-12-14 19:38:00      1      3.0     1.0    NaN       7.0  705.0   \n",
      "36482 2015-12-14 17:44:00      1      0.0     0.0    NaN       7.0  704.0   \n",
      "36483 2015-11-18 11:49:00      0      2.0     0.0    NaN       6.0  607.0   \n",
      "36484 2015-11-18 15:17:00      1      2.0     NaN    NaN       7.0  703.0   \n",
      "36485 2015-12-02 23:58:00      2      3.0     1.0    NaN       7.0  706.0   \n",
      "36486 2015-12-03 02:04:00      2      0.0     0.0    NaN       7.0  702.0   \n",
      "36487 2015-11-08 01:09:00      2      0.0     0.0    NaN       7.0  708.0   \n",
      "36488 2015-11-08 04:38:00      2      0.0     0.0    NaN       7.0  702.0   \n",
      "36489 2015-12-28 13:11:00      0      1.0     0.0    NaN       7.0  702.0   \n",
      "36490 2015-12-28 15:48:00      1      4.0     1.0    NaN       7.0  704.0   \n",
      "36491 2015-12-03 14:45:00      0      0.0     0.0    NaN       7.0  707.0   \n",
      "36492 2015-12-16 19:38:00      1      0.0     0.0    NaN       7.0  707.0   \n",
      "\n",
      "       WARD  ANC  NEIGHBORHOOD_CLUSTER  BLOCK_GROUP  CENSUS_TRACT  \\\n",
      "0         1  2.0                   1.0          0.0        4300.0   \n",
      "1         1  3.0                   0.0          1.0        2701.0   \n",
      "2         1  0.0                   0.0          2.0        3000.0   \n",
      "3         1  2.0                   1.0          3.0        3400.0   \n",
      "4         1  0.0                   0.0          4.0        3000.0   \n",
      "5         1  2.0                   1.0          5.0        3500.0   \n",
      "6         1  2.0                   0.0          6.0        3600.0   \n",
      "7         1  3.0                   0.0          7.0        2701.0   \n",
      "8         1  2.0                   1.0          8.0        4400.0   \n",
      "9         1  2.0                   0.0          9.0        3700.0   \n",
      "10        1  0.0                   0.0          NaN        3100.0   \n",
      "11        1  2.0                   1.0          0.0        4300.0   \n",
      "12        1  3.0                   0.0          1.0        2701.0   \n",
      "13        1  NaN                   NaN          NaN        3800.0   \n",
      "14        1  0.0                   0.0          NaN        2900.0   \n",
      "15        1  NaN                   NaN          NaN        3900.0   \n",
      "16        1  2.0                   0.0          NaN        3700.0   \n",
      "17        1  NaN                   NaN          NaN        3800.0   \n",
      "18        1  0.0                   0.0          NaN        3200.0   \n",
      "19        1  2.0                   1.0          3.0        3400.0   \n",
      "20        1  0.0                   0.0          NaN        2900.0   \n",
      "21        1  0.0                   0.0          NaN        2801.0   \n",
      "22        1  0.0                   0.0          NaN        2802.0   \n",
      "23        1  2.0                   1.0          0.0        4300.0   \n",
      "24        1  0.0                   0.0          NaN        2802.0   \n",
      "25        1  NaN                   NaN          NaN        4001.0   \n",
      "26        1  NaN                   NaN          NaN        4002.0   \n",
      "27        1  0.0                   0.0          NaN        3100.0   \n",
      "28        1  0.0                   0.0          NaN        2802.0   \n",
      "29        1  0.0                   0.0          NaN        2802.0   \n",
      "...     ...  ...                   ...          ...           ...   \n",
      "36463     8  NaN                   NaN          NaN        9810.0   \n",
      "36464     8  NaN                   NaN          NaN        7407.0   \n",
      "36465     8  NaN                   NaN          NaN        9810.0   \n",
      "36466     8  NaN                   NaN          NaN        9700.0   \n",
      "36467     8  NaN                   NaN          NaN        9803.0   \n",
      "36468     8  NaN                   NaN          NaN        7407.0   \n",
      "36469     8  NaN                   NaN          NaN        7409.0   \n",
      "36470     8  NaN                   NaN          NaN        7504.0   \n",
      "36471     8  NaN                   NaN          NaN        7401.0   \n",
      "36472     8  NaN                   NaN          NaN        7504.0   \n",
      "36473     8  NaN                   NaN          NaN        7406.0   \n",
      "36474     8  NaN                   NaN          NaN        7406.0   \n",
      "36475     8  NaN                   NaN          NaN        7503.0   \n",
      "36476     8  NaN                   NaN          NaN        9801.0   \n",
      "36477     8  NaN                   NaN          NaN        7407.0   \n",
      "36478     8  NaN                   NaN          NaN        9803.0   \n",
      "36479     8  NaN                   NaN          NaN        7403.0   \n",
      "36480     8  NaN                   NaN          NaN        7406.0   \n",
      "36481     8  NaN                   NaN          NaN        7304.0   \n",
      "36482     8  NaN                   NaN          NaN        7404.0   \n",
      "36483     8  NaN                   NaN          NaN        7601.0   \n",
      "36484     8  NaN                   NaN          NaN        7407.0   \n",
      "36485     8  NaN                   NaN          NaN        9811.0   \n",
      "36486     8  NaN                   NaN          NaN        7408.0   \n",
      "36487     8  NaN                   NaN          NaN        7301.0   \n",
      "36488     8  NaN                   NaN          NaN        7408.0   \n",
      "36489     8  NaN                   NaN          NaN        7502.0   \n",
      "36490     8  NaN                   NaN          NaN        7403.0   \n",
      "36491     8  NaN                   NaN          NaN       10400.0   \n",
      "36492     8  NaN                   NaN          NaN        9807.0   \n",
      "\n",
      "       VOTING_PRECINCT       CCN       XBLOCK      YBLOCK          START_DATE  \\\n",
      "0                  0.0  14151815  397229.0000  138975.000 2014-08-01 12:00:00   \n",
      "1                  1.0  14174448  396535.8300  140772.030 2014-11-08 10:00:00   \n",
      "2                  2.0  15001508  397162.0000  140182.000 2015-01-03 19:10:00   \n",
      "3                  3.0  15002278  398290.0000  139412.000 2014-12-19 17:00:00   \n",
      "4                  2.0  15009493  397424.0600  140084.430 2015-01-19 11:00:00   \n",
      "5                  3.0  15009496  397928.0000  138989.000 2015-01-19 08:00:00   \n",
      "6                  4.0  15009573  397496.0000  139395.000 2015-01-20 10:31:00   \n",
      "7                  1.0  15009583  396839.0000  140889.000 2015-01-18 14:00:00   \n",
      "8                  0.0  15000583  397829.0000  139066.000 2015-01-01 22:59:00   \n",
      "9                  5.0  15001620  396934.8600  139582.980 2015-01-03 21:45:00   \n",
      "10                 NaN  15003823  397830.0000  140337.000 2015-01-08 08:00:00   \n",
      "11                 0.0  15002329  397113.0000  139035.000 2015-01-04 17:00:00   \n",
      "12                 1.0  15002403  396634.3800  140700.890 2015-01-05 18:00:00   \n",
      "13                 NaN  15004880  396754.0000  139785.000 2015-01-10 21:30:00   \n",
      "14                 NaN  15004919  397373.0000  140476.000 2015-01-10 21:36:00   \n",
      "15                 2.0  15002468  396770.1500  139860.940 2015-01-05 19:07:00   \n",
      "16                 4.0  15002471  397088.0000  139298.000 2015-01-05 19:44:00   \n",
      "17                 NaN  15002485  396835.0000  139570.000 2014-12-07 15:00:00   \n",
      "18                 NaN  15002539  398057.0000  140312.000 2015-01-05 22:50:00   \n",
      "19                 3.0  15002542  398410.0000  138938.000 2015-01-05 23:24:00   \n",
      "20                 NaN  15000753  397585.0000  140742.000 2015-01-02 00:30:00   \n",
      "21                 NaN  15006109  397162.0100  140804.050 2015-01-13 13:00:00   \n",
      "22                 2.0  15007680  397160.4711  140261.678 2015-01-16 13:00:00   \n",
      "23                 0.0  15007728  397229.0000  138854.000 2015-01-16 15:10:00   \n",
      "24                 5.0  15007759  397083.0000  140096.000 2015-01-16 16:35:00   \n",
      "25                 NaN  15005014  396231.0000  139315.000 2015-01-11 03:19:00   \n",
      "26                 NaN  15008651  396326.0000  139306.000 2015-01-18 04:20:00   \n",
      "27                 NaN  15005131  397636.0000  140315.000 2015-01-11 08:00:00   \n",
      "28                 2.0  15005187  396986.3700  140220.860 2015-01-10 20:00:00   \n",
      "29                 5.0  15005226  397083.0000  140096.000 2015-01-11 12:00:00   \n",
      "...                ...       ...          ...         ...                 ...   \n",
      "36463              NaN  15400635  399819.0000  128990.000 2014-12-18 16:41:00   \n",
      "36464              NaN  15400679  401032.0000  132302.000 2015-02-25 12:10:00   \n",
      "36465              NaN  15403280  399688.0000  128741.000 2015-12-14 09:25:00   \n",
      "36466              NaN  15196391  400487.0000  129093.000 2015-12-09 22:02:00   \n",
      "36467              NaN  15204117  399380.0000  129543.000 2015-12-22 20:10:00   \n",
      "36468              NaN  15204315  400879.0000  132468.000 2015-12-23 07:32:00   \n",
      "36469              NaN  15204393  401830.0000  130676.000 2015-12-22 22:00:00   \n",
      "36470              NaN  15189575  401901.0000  133068.000 2015-11-27 17:05:00   \n",
      "36471              NaN  15190731  400366.0000  132181.000 2015-11-29 19:45:00   \n",
      "36472              NaN  15190814  402258.0000  132857.000 2015-11-29 09:00:00   \n",
      "36473              NaN  15175389  401021.0000  132119.000 2015-11-03 16:28:00   \n",
      "36474              NaN  15175602  401326.0000  131794.000 2015-11-03 21:30:00   \n",
      "36475              NaN  15197992  401055.0000  133271.000 2015-12-11 18:00:00   \n",
      "36476              NaN  15198010  400465.0000  129412.000 2015-12-12 09:05:00   \n",
      "36477              NaN  15205590  401032.0000  132302.000 2015-12-25 22:50:00   \n",
      "36478              NaN  15205622  399608.0000  129469.000 2015-12-26 00:05:00   \n",
      "36479              NaN  15190979  402438.0000  131109.000 2015-11-30 12:23:00   \n",
      "36480              NaN  15199204  401004.0000  131818.000 2015-11-07 12:37:00   \n",
      "36481              NaN  15199340  400593.0000  130594.000 2015-12-14 16:44:00   \n",
      "36482              NaN  15199356  401851.0000  131339.000 2015-12-14 16:36:00   \n",
      "36483              NaN  15184202  401893.0000  133657.000 2015-11-16 08:24:00   \n",
      "36484              NaN  15184335  400812.0000  132461.000 2015-11-18 12:10:00   \n",
      "36485              NaN  15192391  400660.0000  129046.000 2015-12-02 22:37:00   \n",
      "36486              NaN  15192419  402497.0000  131749.000 2015-11-28 15:00:00   \n",
      "36487              NaN  15178211  398491.0000  128401.000 2014-03-01 07:00:00   \n",
      "36488              NaN  15178312  402554.0000  131862.000 2015-11-08 03:50:00   \n",
      "36489              NaN  15206758  402596.0000  132669.000 2015-12-27 23:00:00   \n",
      "36490              NaN  15206854  402196.0000  131449.000 2015-12-28 13:00:00   \n",
      "36491              NaN  15192648  400335.0000  131003.000 2015-12-03 12:30:00   \n",
      "36492              NaN  15200607  399283.0000  129409.000 2015-12-16 17:15:00   \n",
      "\n",
      "                 END_DATE  \n",
      "0     2014-09-01 12:03:00  \n",
      "1     2014-11-10 11:08:00  \n",
      "2     2015-01-03 19:20:00  \n",
      "3     2015-01-05 11:30:00  \n",
      "4     2015-01-20 06:59:00  \n",
      "5     2015-01-20 05:00:00  \n",
      "6     2015-01-20 10:50:00  \n",
      "7     2015-01-19 14:30:00  \n",
      "8     2015-01-01 23:00:00  \n",
      "9     2015-01-04 01:15:00  \n",
      "10    2015-01-08 17:30:00  \n",
      "11    2015-01-05 14:00:00  \n",
      "12    2015-01-05 18:05:00  \n",
      "13    2015-01-10 21:31:00  \n",
      "14    2015-01-10 21:38:00  \n",
      "15    2015-01-05 19:08:00  \n",
      "16    2015-01-05 19:55:00  \n",
      "17    2015-01-05 20:08:00  \n",
      "18    2015-01-05 22:53:00  \n",
      "19    2015-01-05 23:26:00  \n",
      "20    2015-01-02 10:45:00  \n",
      "21    2015-01-13 14:28:00  \n",
      "22    2015-01-16 13:15:00  \n",
      "23    2015-01-16 15:15:00  \n",
      "24    2015-01-16 16:38:00  \n",
      "25    2015-01-11 03:25:00  \n",
      "26    2015-01-18 04:35:00  \n",
      "27    2015-01-11 12:00:00  \n",
      "28    2015-01-10 23:30:00  \n",
      "29    2015-01-11 13:10:00  \n",
      "...                   ...  \n",
      "36463 2014-12-18 16:42:00  \n",
      "36464 2015-02-25 15:00:00  \n",
      "36465 2015-12-14 09:45:00  \n",
      "36466 2015-12-09 22:05:00  \n",
      "36467 2015-12-22 20:13:00  \n",
      "36468 2015-12-23 09:53:00  \n",
      "36469 2015-12-23 10:15:00  \n",
      "36470 2015-11-27 19:09:00  \n",
      "36471 2015-11-29 20:45:00  \n",
      "36472 2015-11-30 05:20:00  \n",
      "36473 2015-11-03 17:14:00  \n",
      "36474 2015-11-03 21:35:00  \n",
      "36475 2015-12-11 21:00:00  \n",
      "36476 2015-12-12 10:37:00  \n",
      "36477 2015-12-25 22:52:00  \n",
      "36478 2015-12-26 00:45:00  \n",
      "36479 2015-11-30 12:25:00  \n",
      "36480                 NaT  \n",
      "36481 2015-12-14 16:56:00  \n",
      "36482 2015-12-14 17:40:00  \n",
      "36483 2015-11-18 08:24:00  \n",
      "36484 2015-11-18 12:26:00  \n",
      "36485 2015-12-02 22:39:00  \n",
      "36486 2015-11-28 23:00:00  \n",
      "36487 2015-11-06 16:41:00  \n",
      "36488 2015-11-08 04:23:00  \n",
      "36489 2015-12-28 08:00:00  \n",
      "36490 2015-12-28 13:07:00  \n",
      "36491 2015-12-03 12:45:00  \n",
      "36492 2015-12-16 17:25:00  \n",
      "\n",
      "[36493 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "# convert REPORT_DAT to datetime\n",
    "dc['REPORT_DAT'] = pd.to_datetime(dc['REPORT_DAT'])\n",
    "\n",
    "# convert SHIFT to int\n",
    "shift_mapping = {'day':0, 'evening':1, 'midnight':2}\n",
    "dc['SHIFT'] = pd.to_numeric(dc['SHIFT'].str.lower().map(shift_mapping))\n",
    "\n",
    "# convert OFFENSE to\n",
    "offense_mapping = {'theft/other':0, 'theft f/auto':1, 'burglary':2, 'assault w/dangerous weapon':3, 'robbery':4}\n",
    "dc['OFFENSE'] = pd.to_numeric(dc['OFFENSE'].str.lower().map(offense_mapping))\n",
    "\n",
    "# convert METHOD to\n",
    "method_mapping = {'others':0, 'gun':1}\n",
    "dc['METHOD'] = pd.to_numeric(dc['METHOD'].str.lower().map(method_mapping))\n",
    "\n",
    "# convert BLOCK to\n",
    "block_mapping = {'2100 - 2199 BLOCK OF 14TH STREET NW':0,\n",
    "            '3400 - 3499 BLOCK OF MOUNT PLEASANT STREET NW':1,\n",
    "            '3100 - 3299 BLOCK OF 14TH STREET NW':2,\n",
    "            '400 - 599 BLOCK OF HOWARD PLACE NW':3,\n",
    "            'IRVING STREET NW AND 13TH STREET NW':4,\n",
    "            '2030 - 2199 BLOCK OF 9TH STREET NW':5,\n",
    "            '1200 - 1300 BLOCK OF CLIFTON STREET NW':6,\n",
    "            '3517 - 3648 BLOCK OF 16TH STREET NW':7,\n",
    "            '944 - 960 BLOCK OF FLORIDA AVENUE NW':8,\n",
    "            '2600 - 2798 BLOCK OF 15TH STREET NW':9}\n",
    "dc['BLOCK'] = pd.to_numeric(dc['BLOCK'].str.upper().map(block_mapping))\n",
    "\n",
    "# convert DISTRICT to\n",
    "dc['DISTRICT'] = pd.to_numeric(dc['DISTRICT'])\n",
    "\n",
    "# convert PSA to\n",
    "dc['PSA'] = pd.to_numeric(dc['PSA'])\n",
    "\n",
    "# convert WARD to\n",
    "dc['WARD'] = pd.to_numeric(dc['WARD'])\n",
    "\n",
    "# convert ANC to\n",
    "anc_mapping = {'1a':0, '1b':2, '1d':3}\n",
    "dc['ANC'] = pd.to_numeric(dc['ANC'].str.lower().map(anc_mapping))\n",
    "\n",
    "# convert NEIGHBORHOOD_CLUSTER to\n",
    "neighborhood_cluster_mapping = {'cluster 2':0, 'cluster 3':1}\n",
    "dc['NEIGHBORHOOD_CLUSTER'] = pd.to_numeric(dc['NEIGHBORHOOD_CLUSTER'].str.lower().map(neighborhood_cluster_mapping))\n",
    "\n",
    "# convert BLOCK_GROUP to\n",
    "block_group_mapping = {'004300 1':0, '002701 3':1, '003000 1':2, '003400 2':3, '003000 2':4, '003500 2':5,\n",
    " '003600 3':6, '002701 4':7, '004400 1':8, '003700 2':9}\n",
    "dc['BLOCK_GROUP'] = pd.to_numeric(dc['BLOCK_GROUP'].str.lower().map(block_group_mapping))\n",
    "\n",
    "# convert CENSUS_TRACT to\n",
    "dc['CENSUS_TRACT'] = pd.to_numeric(dc['CENSUS_TRACT'])\n",
    "\n",
    "# convert VOTING_PRECINCT to\n",
    "voting_precinct_mapping = {'precinct 22':0, 'precinct 40':1, 'precinct 39':2, 'precinct 37':3, 'precinct 23':4,\n",
    " 'precinct 36':5}\n",
    "dc['VOTING_PRECINCT'] = pd.to_numeric(dc['VOTING_PRECINCT'].str.lower().map(voting_precinct_mapping))\n",
    "\n",
    "# convert CCN to\n",
    "dc['CCN'] = pd.to_numeric(dc['CCN'])\n",
    "\n",
    "# convert XBLOCK, YBLOCK to \n",
    "dc['XBLOCK'] = pd.to_numeric(dc['XBLOCK'])\n",
    "dc['YBLOCK'] = pd.to_numeric(dc['YBLOCK'])\n",
    "\n",
    "# convert START_DATE, END_DATE to  \n",
    "dc['START_DATE'] = pd.to_datetime(dc['START_DATE'])\n",
    "dc['END_DATE'] = pd.to_datetime(dc['END_DATE'])\n",
    "\n",
    "print dc.info()\n",
    "print dc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to create two dummy columns to represent classify the crime violent or property that can be used for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Give simple, appropriate statistics (range, mode, mean, median, variance, counts, etc.) for the most important attributes and describe what they mean or if you found something interesting. Note: You can also use data from other sources for comparison. Explain the significance of the statistics run and why they are meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualize the most important attributes appropriately (at least 5 attributes). Important: Provide an interpretation for each chart. Explain for each attribute why the chosen visualization is appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Explore relationships between attributes: Look at the attributes via scatter plots, correlation, cross-tabulation, group-wise averages, etc. as appropriate. Explain any interesting relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Identify and explain interesting relationships between features and the class you are trying to predict (i.e., relationships with variables and the target classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Are there other features that could be added to the data or created from existing features? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Features\n",
    "1. Dummy variables are required to indicate if the crime was a violent or property category. These variables would then be used to train a machine learning regression model.\n",
    "2. It would be nice to have the number of police deployed to a police ward for a shift to see if their numbers are correlated with crimes and their types.\n",
    "3. It would be nice to have the police improvement campaigns and dollars by ward to determine if these improvements are correlated with crimes and their types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parking lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REPORT_DAT</th>\n",
       "      <th>SHIFT</th>\n",
       "      <th>OFFENSE</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>PSA</th>\n",
       "      <th>WARD</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NEIGHBORHOOD_CLUSTER</th>\n",
       "      <th>BLOCK_GROUP</th>\n",
       "      <th>CENSUS_TRACT</th>\n",
       "      <th>VOTING_PRECINCT</th>\n",
       "      <th>CCN</th>\n",
       "      <th>XBLOCK</th>\n",
       "      <th>YBLOCK</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>END_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/04/2015 12:05</td>\n",
       "      <td>DAY</td>\n",
       "      <td>THEFT/OTHER</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>2100 - 2199 BLOCK OF 14TH STREET NW</td>\n",
       "      <td>3.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1B</td>\n",
       "      <td>Cluster 3</td>\n",
       "      <td>004300 1</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>Precinct 22</td>\n",
       "      <td>14151815</td>\n",
       "      <td>397229.00</td>\n",
       "      <td>138975.00</td>\n",
       "      <td>08/01/2014 12:00</td>\n",
       "      <td>09/01/2014 12:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/22/2015 09:00</td>\n",
       "      <td>DAY</td>\n",
       "      <td>THEFT F/AUTO</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>3400 - 3499 BLOCK OF MOUNT PLEASANT STREET NW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1D</td>\n",
       "      <td>Cluster 2</td>\n",
       "      <td>002701 3</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>Precinct 40</td>\n",
       "      <td>14174448</td>\n",
       "      <td>396535.83</td>\n",
       "      <td>140772.03</td>\n",
       "      <td>11/08/2014 10:00</td>\n",
       "      <td>11/10/2014 11:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2015 21:20</td>\n",
       "      <td>EVENING</td>\n",
       "      <td>THEFT/OTHER</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>3100 - 3299 BLOCK OF 14TH STREET NW</td>\n",
       "      <td>3.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1A</td>\n",
       "      <td>Cluster 2</td>\n",
       "      <td>003000 1</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>Precinct 39</td>\n",
       "      <td>15001508</td>\n",
       "      <td>397162.00</td>\n",
       "      <td>140182.00</td>\n",
       "      <td>01/03/2015 19:10</td>\n",
       "      <td>01/03/2015 19:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/05/2015 12:44</td>\n",
       "      <td>DAY</td>\n",
       "      <td>THEFT/OTHER</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>400 - 599 BLOCK OF HOWARD PLACE NW</td>\n",
       "      <td>3.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1B</td>\n",
       "      <td>Cluster 3</td>\n",
       "      <td>003400 2</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>Precinct 37</td>\n",
       "      <td>15002278</td>\n",
       "      <td>398290.00</td>\n",
       "      <td>139412.00</td>\n",
       "      <td>12/19/2014 17:00</td>\n",
       "      <td>01/05/2015 11:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/20/2015 07:01</td>\n",
       "      <td>DAY</td>\n",
       "      <td>THEFT F/AUTO</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>IRVING STREET NW AND 13TH STREET NW</td>\n",
       "      <td>3.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1A</td>\n",
       "      <td>Cluster 2</td>\n",
       "      <td>003000 2</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>Precinct 39</td>\n",
       "      <td>15009493</td>\n",
       "      <td>397424.06</td>\n",
       "      <td>140084.43</td>\n",
       "      <td>01/19/2015 11:00</td>\n",
       "      <td>01/20/2015 06:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         REPORT_DAT    SHIFT       OFFENSE  METHOD  \\\n",
       "0  03/04/2015 12:05      DAY   THEFT/OTHER  OTHERS   \n",
       "1  01/22/2015 09:00      DAY  THEFT F/AUTO  OTHERS   \n",
       "2  01/03/2015 21:20  EVENING   THEFT/OTHER  OTHERS   \n",
       "3  01/05/2015 12:44      DAY   THEFT/OTHER  OTHERS   \n",
       "4  01/20/2015 07:01      DAY  THEFT F/AUTO  OTHERS   \n",
       "\n",
       "                                           BLOCK  DISTRICT    PSA  WARD ANC  \\\n",
       "0            2100 - 2199 BLOCK OF 14TH STREET NW       3.0  305.0     1  1B   \n",
       "1  3400 - 3499 BLOCK OF MOUNT PLEASANT STREET NW       4.0  408.0     1  1D   \n",
       "2            3100 - 3299 BLOCK OF 14TH STREET NW       3.0  302.0     1  1A   \n",
       "3             400 - 599 BLOCK OF HOWARD PLACE NW       3.0  306.0     1  1B   \n",
       "4            IRVING STREET NW AND 13TH STREET NW       3.0  302.0     1  1A   \n",
       "\n",
       "  NEIGHBORHOOD_CLUSTER BLOCK_GROUP  CENSUS_TRACT VOTING_PRECINCT       CCN  \\\n",
       "0            Cluster 3    004300 1        4300.0     Precinct 22  14151815   \n",
       "1            Cluster 2    002701 3        2701.0     Precinct 40  14174448   \n",
       "2            Cluster 2    003000 1        3000.0     Precinct 39  15001508   \n",
       "3            Cluster 3    003400 2        3400.0     Precinct 37  15002278   \n",
       "4            Cluster 2    003000 2        3000.0     Precinct 39  15009493   \n",
       "\n",
       "      XBLOCK     YBLOCK        START_DATE          END_DATE  \n",
       "0  397229.00  138975.00  08/01/2014 12:00  09/01/2014 12:03  \n",
       "1  396535.83  140772.03  11/08/2014 10:00  11/10/2014 11:08  \n",
       "2  397162.00  140182.00  01/03/2015 19:10  01/03/2015 19:20  \n",
       "3  398290.00  139412.00  12/19/2014 17:00  01/05/2015 11:30  \n",
       "4  397424.06  140084.43  01/19/2015 11:00  01/20/2015 06:59  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Show the file headers\n",
    "dc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Shift\n",
    "##### TO DO:\n",
    "* Frequency plot.  Plot the number of crimes reported for each shift.  Which shift has the most activity?\n",
    "* Encode the shift data to follow the frequency plot: -1 = the shift before the most activity, 0 = the shift with the most activity, +1 = the shift after the most activity\n",
    "\n",
    "### Offense\n",
    "##### TO DO:\n",
    "* Frequency plot.  Plot the number instances of each offense and compare to the 2015 published numbers.  We *should* match!\n",
    "* Encode the offense nominal values to numeric values.  May have to be an arbitrary coding scheme\n",
    "* Calculate rate for each offense given the published estimated population value of 672,228 (use the 'per 100,000' criterion).\n",
    "  * For example Homicide rate = (# Homicides) / (population / 100,000) = 162 / 6.72228 = 24.09.  Compare to published value (24).\n",
    "* That gives us odds of being murdered: 24.09/100000 = 0.024%\n",
    "* Calculate odds for each offense type.\n",
    "* Now we have a continuous response variable we can use for regression/PCA/logistic/ etc.\n",
    "\n",
    "### Method\n",
    "##### TO DO:\n",
    "* Frequency plot.\n",
    "* This one should be interesting because this leads to additional options of predicting if a gun or knife will be involved, etc.\n",
    "* Compare to published values about gun-related crimes\n",
    "\n",
    "### Block\n",
    "##### TO DO:\n",
    "* Harvest the street name from the value and put in its own column\n",
    "* Is there a \"most dangerous street\"?\n",
    "\n",
    "### District\n",
    "##### TO DO:\n",
    "* There are missing values for District.  Since the districts have a geo-physical separation, we **should** be able to impute the missing district value given the coordinates of the crime.\n",
    "  * Compute the mean XBlock and YBlock values for each district\n",
    "  * For each record missing a District value, compare the record's XBlock and YBlock to each District mean and report the district that is closest.  Use that value to fill in the blank\n",
    "* Once the missing values are imputed, perform a frequency plot (by offense?).\n",
    "* Can we get the estimated number of police officers per District? Estimated population?\n",
    "\n",
    "### PSA (Police Service Area)\n",
    "##### TO DO:\n",
    "* Similar to District.\n",
    "* Compute mean XBlock/YBlock for each PSA\n",
    "* Estimate the PSA for the missing values based on proximity\n",
    "* Frequency plot (by offense?)\n",
    "* Can we get the estimated number of officers per PSA?  estimated population?\n",
    "\n",
    "### Ward\n",
    "##### TO DO:\n",
    "* Frequency plot (by offense?)\n",
    "* Which police districts are involved?\n",
    "\n",
    "### ANC (Advisory Neighborhood Commission)\n",
    "##### TO DO:\n",
    "* Frequency plot (by offense?)\n",
    "* Which police district(s) are involved?\n",
    "\n",
    "### Neighborhood Cluster\n",
    "* Not sure what to do with this.  Ideas?\n",
    "* Separate the numeric value from the label and place in its own column\n",
    "\n",
    "### Block Group\n",
    "* This value appears to be based on the CENSUS_TRACT variable, but with higher resolution.\n",
    "* The current value uses a space character to separate the block group from the CENSUS_TRACT value\n",
    "##### TO DO:\n",
    "* Recommend replacing the space with a \".\" and turn the value into a floating point number.  It still retains the information.\n",
    "* Frequency plot (by offense?)\n",
    "* What police district(s) are involved?\n",
    "\n",
    "### Census Tract\n",
    "* Appears to be related to BLOCK_GROUP.\n",
    "* Not sure what to do with this\n",
    "\n",
    "### Voting Precinct\n",
    "##### TO DO:\n",
    "* The field values have a common label in them.  Separate out the numeric precinct number into its own field.\n",
    "* This field has missing values, but due to political \"gerry-mandering\", the shapes of the voting precincts may not be conducive to imputing missing values by proximity.\n",
    "* Can we get an indication whether these precincts are Republican or Democrat?\n",
    "\n",
    "### CCN (Criminal Complaint Number)\n",
    "##### TO DO:\n",
    "* Since these are the actual \"case\" numbers, it would be nice to see if we could get publically-available data for the cases (perpetrator information, victim demographics, etc.)\n",
    "\n",
    "### Start and End dates\n",
    "* These values represent the span of time in which the crime *might* have been committed.\n",
    "* There are a lot of missing values for the END_DATE field.  Examine these to see if, perhaps, they should be the same as the START_DATE value.\n",
    "  * This might be imputed if the reporting date coincides with the Start date.\n",
    "* There are also incorrect values (I noticed a date of 1915, for example - is it truly a 100-year-old cold case, or did the person simply enter the wrong century?)\n",
    "\n",
    "### Coordinates (XBLOCK, YBLOCK)\n",
    "One obvious visualization tool would be to plot the geo-spatial relationship of the data, and, fortunately, this dataset provides the *approximate* location of the crime (presumably to preserve the privacy of the victim(s)) in grid coordinates (XBLOCK = East offset from the \"Origin\"; YBLOCK = North offset from the \"Origin\").  The question is, where is that Origin?\n",
    "\n",
    "![Identity of Coordinate Origin](images/Coordinates.png \"Origin for Location Coordinates\")\n",
    "<p style='text-align:center'>(*Screen capture of description of coordinate origin*)</p>\n",
    "\n",
    "On the download page for the datasets, next to the \"Map Coordinates\" field selector, there is a description of the origin, which states that the values are in the Maryland State Plane, NAD 83 map projection.  Further research led to a web page that defined the [Maryland coordinate system](http://www.mgs.md.gov/geology/maryland_coordinate_system.html \"Maryland State Coordinate System\")\n",
    "\n",
    "The coordinate system is a Lambert conformal conical projection with two standard parallels (latitudes). This attempts to reduce the distortion of trying to map a flat plane on a curved surface.  With the coordinate system defined, we can then reverse the projection and re-project to a different system that can be used with other mapping/GIS tools.  The transformation methodology came from the National Geospatial Intelligence Agency (NGA), but a more concise explanation of the method was provided by this website: http://www.linz.govt.nz/data/geodetic-system/coordinate-conversion/projection-conversions/lambert-conformal-conic-geographic \n",
    "\n",
    "In order to do the coordinate transformations, we need to get several parameters set up first.\n",
    "\n",
    "|Parameter|Description|Value|\n",
    "|:--------|:----------|:----|\n",
    "|a|Semi-major axis of reference ellipsoid (meters)|6378137 (Maryland uses the GRS80 reference)|\n",
    "|f|Ellipsoidal flattening|1/298.257222101 (GRS80)|\n",
    "|&theta;<sub>1</sub>|Latitude of first standard parallel (degrees)|38.3 (38&deg; 18' from Maryland definition)|\n",
    "|&theta;<sub>2</sub>|Latitude of second standard parallel (degrees)|39.45 (39&deg; 27' from Maryland definition)|\n",
    "|&theta;<sub>0</sub>|Origin Latitude (degrees)|37.66667 (North 37&deg; 40' from Maryland definition)|\n",
    "|&lambda;<sub>0</sub>|Origin Longitude (degrees)|-81.52918855 (West 81&deg; 31' 45.07877\" from Maryland definition)|\n",
    "|N<sub>0</sub>|False Northing (meters)|0.0 (from Maryland definition)|\n",
    "|E<sub>0</sub>|False Easting (meters)|400,000 (from Maryland definition)|\n",
    "\n",
    "From these, we can derive the projection constants\n",
    "\n",
    "|Constant|Derivation|Value|\n",
    "|-------|-----------|-----|\n",
    "|e      |$\\sqrt{2f - f^2}$ | 0.081819191|\n",
    "|m<sub>i</sub>|$\\frac{\\cos \\theta_i}{\\sqrt{1-e^2\\sin^2 \\theta_i}}$|m<sub>1</sub>=0.785787341<br>m<sub>2</sub>=0.773225009|\n",
    "|t<sub>i</sub>|$\\frac{\\tan \\left[(\\frac{\\pi}{4})-(\\frac{\\theta_i}{2})\\right]}{\\left(\\frac{1-e\\sin\\theta_i}{1+e\\sin\\theta_i}\\right)^\\frac{e}{2}}$|t<sub>0</sub>=0.493354296<br>t<sub>1</sub>=0.486512044<br>t<sub>2</sub>=0.474178631|\n",
    "|n      |$\\frac{\\ln m_1 - \\ln m_2}{\\ln t_1 - \\ln t_2}$|0.627634132|\n",
    "|F      |$\\frac{m_1}{n(t_1)^n}$|1.967837417|\n",
    "|&rho;<sub>0</sub>  |$a F t_0^n$|8055622.737|\n",
    "\n",
    "Now, for each point (i) in our dataset, we must perform the following steps:\n",
    "1. Adjust the North offset using the false northing - our false northing is 0, so this step is skipped\n",
    "2. Adjust the East offset using the false easting: $E_i' = E_i - E_0$\n",
    "3. $\\rho_i' = \\sqrt{(E_i')^2 + (\\rho_0-N_i)^2}$\n",
    "4. $t_i'= \\left(\\frac{\\rho_i'}{a F}\\right)^\\frac{1}{n}$\n",
    "5. $\\gamma_i' = \\tan^{-1}\\left(\\frac{E_i'}{\\rho_0-N_i}\\right)$\n",
    "6. $\\lambda_i = \\frac{\\gamma_i'}{n}+\\lambda_0$ (This is the longitude of the location\n",
    "7. The calculation for latitude is iterative.\n",
    " 1. $\\theta_{i0} = \\frac{\\pi}{2}-2\\tan^{-1}(t_i')$ (This is our initial estimate of latitude)\n",
    " 2. $\\theta_{i,j} = \\frac{\\pi}{2}-2\\tan^{-1}\\left[t_i'\\left(\\frac{1-e\\sin\\theta_{i,j-1}}{1+e\\sin\\theta_{i,j-1}}\\right)\\right]$ (We use the previous estimate to create a new estimate)\n",
    " 3. Repeat the previous step until the difference in estimates is negligible (this typically takes three iterations)\n",
    "8. $\\theta_i$ is our estimate of the latitude for the location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F': 1.9678374170334183,\n",
       " 'm1': 0.7857873413486276,\n",
       " 'm2': 0.7732250089525023,\n",
       " 'n': 0.6276341323554715,\n",
       " 'p0': 8055622.737265018,\n",
       " 't0': 0.49335429608783643,\n",
       " 't1': 0.48651204380528484,\n",
       " 't2': 0.4741786305194415}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#  Build a class that handles generic reference ellipsoid parameters in case we have multiple coordinate systems to deal with\n",
    "class refEllipsoid:\n",
    "    #  a = Equatorial radius (meters)\n",
    "    #  f = Flattening (the degree to which the polar radius is compressed compared to the equatorial radius)\n",
    "    #  b = Polar radius (meters): f = (a-b)/a; af = a-b; af - a = -b; b = a - af = a(1-f)\n",
    "    #  e2 = First eccentricity squared: 1 − b2/a2 = 2f − f2\n",
    "    #  e = First eccentricity\n",
    "    #  p2 = Second eccentricity squared: a2/b2 − 1 = f(2 − f)/(1 − f)^2\n",
    "    def __init__(self, equator, flattening):\n",
    "        #  Provided\n",
    "        self.a = float(equator)\n",
    "        self.f = 1.0/float(flattening)\n",
    "        \n",
    "        #  Derived\n",
    "        self.b = self.a * (1.0 - self.f)\n",
    "        self.e2 = (2.0 * self.f) - self.f**2\n",
    "        self.e = math.sqrt(self.e2)\n",
    "        self.p2 = (self.a**2 / self.b**2) - 1.0\n",
    "\n",
    "GRS80 = refEllipsoid(6378137.0,298.257222101)  #  Define the Geodetic Reference System 1980 (GRS80) ellipsoid\n",
    "\n",
    "#  Function to convert individual angular components to floating-point degrees\n",
    "def DMS(degrees, minutes, seconds):\n",
    "    sign = 1.0\n",
    "    if degrees < 0:\n",
    "        sign = -1.0\n",
    "    return sign * (math.fabs(float(degrees)) + (float(minutes) / 60.0) + (float(seconds) / 3600.0))\n",
    "\n",
    "class coordOrigin:\n",
    "    origin = {'lat':0.0, 'lon': 0.0}\n",
    "    parallel = {1:0.0, 2:0.0}\n",
    "    false = {'n':0.0, 'e':0.0}\n",
    "                        \n",
    "    def __init__(self,latOrigin,lonOrigin,parallel1,parallel2,northing,easting):\n",
    "        self.origin['lat'] = math.radians(latOrigin)\n",
    "        self.origin['lon'] = math.radians(lonOrigin)\n",
    "        self.parallel[1] = math.radians(parallel1)\n",
    "        self.parallel[2] = math.radians(parallel2)\n",
    "        self.false['n'] = float(northing)\n",
    "        self.false['e'] = float(easting)\n",
    "        \n",
    "#  Define the origin for the Maryland state coordinate system\n",
    "MD = coordOrigin(DMS(37,40,0),DMS(-81,31,45.07877),DMS(38,18,0),DMS(39,27,0),0,400000)\n",
    "\n",
    "class Lambert:\n",
    "    def __init__(self):\n",
    "        self.m1 = Lambert._m(MD.parallel[1])\n",
    "        self.m2 = Lambert._m(MD.parallel[2])\n",
    "        self.t0 = Lambert._t(MD.origin['lat'])\n",
    "        self.t1 = Lambert._t(MD.parallel[1])\n",
    "        self.t2 = Lambert._t(MD.parallel[2])\n",
    "        self.n = (math.log(self.m1) - math.log(self.m2))/(math.log(self.t1)-math.log(self.t2))\n",
    "        self.F = self.m1 / (self.n * self.t1**self.n)\n",
    "        self.p0 = GRS80.a * self.F * self.t0**self.n\n",
    "        \n",
    "    @staticmethod\n",
    "    def _m(parallel):\n",
    "        return math.cos(float(parallel)) / math.sqrt(1.0 - (GRS80.e2 * math.sin(float(parallel))**2))\n",
    "\n",
    "    @staticmethod\n",
    "    def _t(parallel):\n",
    "        return math.tan((math.pi / 4.0) - (float(parallel) / 2.0)) / ((1 - (GRS80.e * math.sin(float(parallel)))) / (1 + (GRS80.e * math.sin(float(parallel)))))**(GRS80.e / 2.0)\n",
    "\n",
    "Projection = Lambert()\n",
    "Projection.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Create a python function to perform these calculations and add the resulting columns to the data frame\n",
    "#  I did this in Excel to make sure the process worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization - Map\n",
    "After transforming the coordinates to Geodetic (Latitude/Longitude) we can plot the locations with a mapping/GIS tool.  In this example, we used a tool developed by Mercury Solutions, Inc. (Tom Elkins' company) that plots multiple tactical data sources.\n",
    "![Crime data on map](images/Data_on_Map.png \"Crime locations on DC Map\")\n",
    "\n",
    "### Data By Geo-Political Identifiers\n",
    "#### Political Ward\n",
    "![Crimes by Ward](images/CrimesByWard.png \"Crimes by Ward\")\n",
    "#### Police District\n",
    "![Crimes by Police District](images/DistrictBorderOverlay.png \"Crimes by Police District\")\n",
    "<p style='text-align:center'>Police District Map from http://mpdc.dc.gov/sites/default/files/dc/sites/mpdc/page_content/images/districtmap_2012.jpg\n",
    "Modified in PowerPoint to remove the background color, and resized to fit over the data plot</p>\n",
    "#### Advisory Neighborhood Commission\n",
    "![Crimes by ANC](images/CrimesByANC.png \"Crimes by ANC\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:10px;'>\n",
    "<h3>Exceptional Work (<b>10 points total</b>)</h3>\n",
    "    <ul><li>You have free reign to provide additional analyses.</li>\n",
    "    <li>One idea: implement dimensionality reduction, then visualize and interpret the results.</li></ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
